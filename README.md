
# ğŸš€ Multi-Model YOLO Object Detection & Performance Benchmark

This project compares multiple YOLO models (**YOLOv8, YOLOv9, YOLOv10, YOLOv11, YOLOv12**) on a real-world traffic surveillance video.  
It runs all models in parallel, generates **side-by-side visual outputs**, and computes **performance statistics** (FPS, people count, car count) to help you choose the best-performing model.

---

## ğŸ“Œ Features

âœ… Loads and runs **multiple YOLO models** on GPU (if available)  
âœ… Processes a **video frame-by-frame** and annotates detections  
âœ… Displays **people & car counts** for each model  
âœ… Measures **FPS (frames per second)** for speed benchmarking  
âœ… Generates a **3x2 grid video output** showing all models side by side  
âœ… Prints a **performance summary** with average FPS and counts  

---

## ğŸ› ï¸ Installation & Requirements

Install dependencies if not already installed in your environment:

```bash
pip install ultralytics opencv-python
````

**Tested On:**

* **Python:** 3.10+
* **Ultralytics YOLO:** v8+
* **OpenCV:** 4.11+
* **Torch:** CUDA-enabled GPU recommended for speed

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ notebook.ipynb             # Kaggle Notebook (or .py file)
â”œâ”€â”€ /kaggle/input/lari-adda/   # Input folder containing `adda.mp4`
â”œâ”€â”€ /kaggle/input/yolo11/      # Pretrained YOLOv11 model weights
â”œâ”€â”€ /kaggle/input/yolov12m/    # Pretrained YOLOv12 model weights
â””â”€â”€ output2.mp4                # Generated comparison video (saved after processing)
```

---

## â–¶ï¸ How to Run

1. Place your input video in `/kaggle/input/lari-adda/adda.mp4`
2. Run the notebook (or Python script)
3. The code will:

   * Load all YOLO models
   * Process each frame through each model
   * Write a 3x2 comparison grid video as `output2.mp4`
   * Print a **performance summary**

---

## ğŸ“Š Sample Output (Performance Summary)

After running, you will see a performance report like this:

```
ğŸ“Š Model Performance Summary:

ğŸ”¹ YOLOv8n  â†’ Avg FPS: 56.4 | Avg People: 3.8 | Avg Cars: 2.1
ğŸ”¹ YOLOv9c  â†’ Avg FPS: 49.2 | Avg People: 4.0 | Avg Cars: 2.2
ğŸ”¹ YOLOv10n â†’ Avg FPS: 61.5 | Avg People: 3.7 | Avg Cars: 2.0
ğŸ”¹ YOLOv11m â†’ Avg FPS: 44.3 | Avg People: 4.1 | Avg Cars: 2.3
ğŸ”¹ YOLOv12m â†’ Avg FPS: 42.8 | Avg People: 4.3 | Avg Cars: 2.5
```

* **Avg FPS** â†’ Higher = faster inference
* **Avg People / Cars** â†’ Higher = better detection recall

---

## ğŸ“¹ Output Video

The final video shows all modelsâ€™ detections **side-by-side** in a 3x2 grid format, with each frame annotated like this:

```
YOLOv8n | People: 3 Cars: 2 | FPS: 58.2
```

This allows you to **visually inspect** detection quality and compare models.

---

## ğŸ† How to Choose the Best Model

* If **speed** matters (real-time processing) â†’ Choose the model with **highest FPS**
* If **accuracy** matters (maximum detections) â†’ Choose the model with **highest people/car counts**
* For **balanced performance** â†’ Choose a model with a good trade-off between FPS & detection count

---

## ğŸ“Œ Future Improvements

* Add **precision/recall/mAP** evaluation using labeled ground truth data
* Support for **batch inference** for faster processing
* Integrate **model weights auto-download** from Ultralytics Hub
* Deploy as a **web dashboard** to visualize results interactively

---

## ğŸ‘¨â€ğŸ’» Author

Developed by **Zuhaib Hussain Butt**
ğŸ’¼ Lecturer in Data Science | Generative AI Enthusiast
ğŸ“ Pakistan | ğŸ”— [LinkedIn]([https://linkedin.com](https://www.linkedin.com/in/zuhaib-hussain-butt-6628141a4/))

```
